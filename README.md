# Parameter--Efficient Fine--Tuning-of GPT2 LLM
This is to compare a variety of ways to fine-tune a pretrained GPT2 model on different datasets.

Supported Methods:
1. LORA: https://arxiv.org/abs/2106.09685
2. Prompt Tuning: https://arxiv.org/abs/2104.08691


![image](https://github.com/yiqiaoc11/Efficient-Fine-Tuning-of-GPT2-LLM/assets/30539007/dc8a9dfc-794d-47c1-8fe1-5cc75ba58cef)

![image](https://github.com/yiqiaoc11/Efficient-Fine-Tuning-of-GPT2-LLM/assets/30539007/46ef618b-8c13-4dad-ad1c-a263ac566387)

